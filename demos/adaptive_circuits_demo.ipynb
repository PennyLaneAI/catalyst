{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fbc188e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: optax in /home/tzung-han.juang/.local/lib/python3.10/site-packages (0.2.2)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /home/tzung-han.juang/.local/lib/python3.10/site-packages (from optax) (2.1.0)\n",
      "Requirement already satisfied: chex>=0.1.86 in /home/tzung-han.juang/.local/lib/python3.10/site-packages (from optax) (0.1.86)\n",
      "Requirement already satisfied: jax>=0.1.55 in /home/tzung-han.juang/.local/lib/python3.10/site-packages (from optax) (0.4.23)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /home/tzung-han.juang/.local/lib/python3.10/site-packages (from optax) (0.4.23)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/tzung-han.juang/.local/lib/python3.10/site-packages (from optax) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/tzung-han.juang/.local/lib/python3.10/site-packages (from chex>=0.1.86->optax) (4.12.2)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /home/tzung-han.juang/.local/lib/python3.10/site-packages (from chex>=0.1.86->optax) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /home/tzung-han.juang/.local/lib/python3.10/site-packages (from jax>=0.1.55->optax) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum in /home/tzung-han.juang/.local/lib/python3.10/site-packages (from jax>=0.1.55->optax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /home/tzung-han.juang/.local/lib/python3.10/site-packages (from jax>=0.1.55->optax) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbbd8a0f",
   "metadata": {},
   "source": [
    "# Variational Quantum Eigensolver\n",
    "\n",
    "The Variational Quantum Eigensolver (VQE) is a widely used quantum algorithm with applications in quantum chemistry and portfolio optimization problems. It is an application of the [Ritz variational principle](https://en.wikipedia.org/wiki/Ritz_method), where a quantum computer is trained to prepare the ground state of a given molecule. In this demo we follow PennyLane's demos, [A brief overview of VQE](https://pennylane.ai/qml/demos/tutorial_vqe.html) and [Adaptive circuits for quantum chemistry](https://pennylane.ai/qml/demos/tutorial_adaptive_circuits.html), to learn how to implement VQE and Adaptive VQE problems in Catalyst by adapting the PennyLane code.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d24a0319",
   "metadata": {},
   "source": [
    "## Importing PennyLane and Catalyst\n",
    "In order to use PennyLane with the Catalyst compiler, we need to import several important components:\n",
    "\n",
    "- The [PennyLane](https://pennylane.ai/) framework in order to access the base QML API,\n",
    "- The [Catalyst](https://xanaduai-pennylane-mlir.readthedocs-hosted.com/en/latest/) Python package,\n",
    "- The JAX and PennyLane versions of NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "531e037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catalyst\n",
    "from catalyst import qjit\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import functools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f31835ab",
   "metadata": {},
   "source": [
    "## VQE for the trihydrogen cation $H_3^{+}$ with Catalyst\n",
    "\n",
    "The algorithm takes a molecular Hamiltonian and a parametrized circuit preparing the trial state of the molecule. The cost function is defined as the expectation value of the Hamiltonian computed in the trial state. With VQE, the lowest energy state (also called the ground state) of the Hamiltonian can be computed using an iterative optimization of the cost function. In PennyLane, this optimization is performed by a classical optimizer which (in principle) leverages a quantum computer to evaluate the cost function and calculate its gradient at each optimization step.\n",
    "\n",
    "In this section, you will learn how to implement the VQE algorithm for the trihydrogen cation $H_3^{+}$ (three hydrogen atoms sharing two electrons) using Catalyst. We will break the implementation into three steps:\n",
    "\n",
    "1. Find molecular Hamiltonian for $H_3^{+}$.\n",
    "2. Prepare trial ground step (ansatz).\n",
    "3. Minimize the expectation value of the Hamiltonian.\n",
    "\n",
    "\n",
    "### Standard PennyLane\n",
    "\n",
    "Let's first go over the implementation of these steps in the PennyLane demo on [A brief overview of VQE](https://pennylane.ai/qml/demos/tutorial_vqe.html).\n",
    "\n",
    "**Step 1**\n",
    "\n",
    "The first step is to specify the molecule we want to simulate. This is done by providing a list with the symbols of the constituent atoms and a one-dimensional array with the corresponding nuclear coordinates in atomic units. In the next step, we can build the electronic Hamiltonian of the hydrogen molecule using the `molecular_hamiltonian()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940f918c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qubits: 6\n"
     ]
    }
   ],
   "source": [
    "symbols = [\"H\", \"H\", \"H\"]\n",
    "coordinates = np.array([0.028, 0.054, 0.0, 0.986, 1.610, 0.0, 1.855, 0.002, 0.0])\n",
    "\n",
    "# Building the molecular hamiltonian for the trihydrogen cation\n",
    "hamiltonian, qubits = qml.qchem.molecular_hamiltonian(symbols, coordinates, charge=1)\n",
    "\n",
    "print(f\"qubits: {qubits}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03742823",
   "metadata": {},
   "source": [
    "In PennyLane, we can perform steps 2 and 3 in a few lines of code using the [qml.GradientDescentOptimizer](https://docs.pennylane.ai/en/stable/code/api/pennylane.GradientDescentOptimizer.html) optimizer:\n",
    "\n",
    "**Step 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfe23043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Hartree-Fock State \n",
    "hf = qml.qchem.hf_state(electrons=2, orbitals=6)\n",
    "\n",
    "# Define the device, using lightning.qubit device\n",
    "dev = qml.device(\"lightning.qubit\", wires=qubits)\n",
    "\n",
    "def stopping_condition(obj):\n",
    "    return obj.name not in [\"BasisState\"]\n",
    "\n",
    "def decompose(stopping_condition, func):\n",
    "    return qml.devices.preprocess.decompose(func, stopping_condition, skip_initial_state_prep=False)\n",
    "\n",
    "@functools.partial(decompose, stopping_condition)\n",
    "@qml.qnode(dev, diff_method=\"adjoint\")\n",
    "def cost_func(params):\n",
    "    qml.BasisState(hf, wires=range(qubits))\n",
    "    qml.DoubleExcitation(params[0], wires=[0, 1, 2, 3])\n",
    "    qml.DoubleExcitation(params[1], wires=[0, 1, 4, 5])\n",
    "    return qml.expval(hamiltonian)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19098036",
   "metadata": {},
   "source": [
    "**Step 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "250df3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step: 0, Energy: -1.26094188\n",
      "--- Step: 1, Energy: -1.26779949\n",
      "--- Step: 2, Energy: -1.27110529\n",
      "--- Step: 3, Energy: -1.27269203\n",
      "--- Step: 4, Energy: -1.27345238\n",
      "--- Step: 5, Energy: -1.27381655\n",
      "--- Step: 6, Energy: -1.27399097\n",
      "--- Step: 7, Energy: -1.27407452\n",
      "--- Step: 8, Energy: -1.27411455\n",
      "--- Step: 9, Energy: -1.27413373\n",
      "Final angle parameters: [0.18356278 0.1841571 ]\n"
     ]
    }
   ],
   "source": [
    "def workflow(params, ntrials):\n",
    "    opt = qml.GradientDescentOptimizer(stepsize=0.4)\n",
    "\n",
    "    for n in range(ntrials):\n",
    "        params, prev_energy = opt.step_and_cost(cost_func, params)\n",
    "        print(f\"--- Step: {n}, Energy: {cost_func(params):.8f}\")\n",
    "\n",
    "    return params\n",
    "\n",
    "theta = workflow(np.array([0.0, 0.0]), 10)\n",
    "\n",
    "print(f\"Final angle parameters: {theta}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ec26eee",
   "metadata": {},
   "source": [
    "### PennyLane with Catalyst\n",
    "\n",
    "In Catalyst, you can define a quantum function using `qml.qnode`. In PennyLane, Hamiltonian objects are not yet supported as a JAX data-type, but this support is planned for the future. Hence, you need to construct the Hamiltonian using `qml.Hamiltonian` in your `cost_func` as follows:\n",
    "\n",
    "**Step 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9049c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hartree-Fock State: [1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "hf = qml.qchem.hf_state(electrons=2, orbitals=6)\n",
    "print(f\"The Hartree-Fock State: {hf}\")\n",
    "\n",
    "@functools.partial(decompose, stopping_condition)\n",
    "@qml.qnode(qml.device(\"lightning.qubit\", wires=qubits))\n",
    "def catalyst_cost_func(params):\n",
    "    qml.BasisState(hf, wires=range(qubits))\n",
    "    qml.DoubleExcitation(params[0], wires=[0, 1, 2, 3])\n",
    "    qml.DoubleExcitation(params[1], wires=[0, 1, 4, 5])\n",
    "    return qml.expval(\n",
    "        qml.Hamiltonian(np.array(hamiltonian.coeffs), hamiltonian.ops)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ee485d3",
   "metadata": {},
   "source": [
    "**Step 3**\n",
    "\n",
    "Catalyst does not provide built-in optimizers, however any optimizer that is JAX-compatible will work inside a `qjit` function. We will see this a bit later; here, we will implement our own simple gradient descent optimization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bb71f4b",
   "metadata": {},
   "source": [
    "We can JIT compiler the whole workflow taking advantage of the QJIT compatible for-loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35dd44c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final angle parameters: [0.18356278 0.1841571 ]\n"
     ]
    }
   ],
   "source": [
    "@qjit\n",
    "def grad_descent(params, ntrials: int, stepsize: float):\n",
    "    diff = catalyst.grad(catalyst_cost_func, argnum=0)\n",
    "    theta = params\n",
    "\n",
    "     # for_loop can only be used in JIT mode\n",
    "    @catalyst.for_loop(0, ntrials, 1)\n",
    "    def single_step(i, theta):\n",
    "        h = diff(theta)\n",
    "        return theta - h * stepsize\n",
    "\n",
    "    return single_step(theta)\n",
    "\n",
    "theta = grad_descent(jnp.array([0.0, 0.0]), 10, 0.4)\n",
    "\n",
    "print(f\"Final angle parameters: {theta}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "102382c3",
   "metadata": {},
   "source": [
    "#### Using JAX Optimizer\n",
    "\n",
    "So far, we've learned how to implement the gradient descent optimizer using Catalyst's control-flows and the `grad` operations. However, there's another way to calculate this optimizer using [Optax](https://optax.readthedocs.io/en/stable/index.html). In the following example, we'll utilize the `optax.sgd` function to optimize the parameters of the `cost_func`.\" We start by importing the necessary tools from Optax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c70c6f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "from jax.lax import fori_loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f62fe520",
   "metadata": {},
   "source": [
    "The `sgd` method helps compute the optimizer by taking a smooth function of the form `gd_fun(params, *args, **kwargs)` and computing its value <i>and</i> its gradient. To optimize `params` iteratively, you need to use `jax.lax.fori_loop` to loop over the gradient descent steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01aec21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final angle parameters: [0.18356278 0.1841571 ]\n"
     ]
    }
   ],
   "source": [
    "@qjit\n",
    "def workflow():\n",
    "    def gd_fun(params):\n",
    "        diff = catalyst.grad(catalyst_cost_func, argnum=0)\n",
    "        return catalyst_cost_func(params), diff(params)\n",
    "\n",
    "    opt = optax.sgd(learning_rate=0.4)\n",
    "    \n",
    "    def gd_update(i, args):\n",
    "        param, state = args\n",
    "        _, gradient = gd_fun(param)\n",
    "        (updates, state) = opt.update(gradient, state)\n",
    "        param = optax.apply_updates(param, updates)\n",
    "        return (param, state)\n",
    "\n",
    "    params = jnp.array([0.0, 0.0])\n",
    "    state = opt.init(params)\n",
    "    upper = 10\n",
    "    (params, _) = fori_loop(0, upper, gd_update, (params, state))\n",
    "    return params\n",
    "\n",
    "theta = workflow()\n",
    "\n",
    "print(f\"Final angle parameters: {theta}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26ccdb58",
   "metadata": {},
   "source": [
    "There is no significant difference between a custom implementation of the gradient descent algorithm and `optax.sgd`, since the underlying implementation is very similar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f18220fe",
   "metadata": {},
   "source": [
    "#### JIT and AOT Compilation Modes\n",
    "To show case just-in-time (JIT) and ahead-of-time (AOT) compilation modes in Catalyst, let's perform a single step of the gradient descent algorithm and use the Python for-loop to optimize these parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb5fef85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step: 0, Energy: -1.26094188\n",
      "--- Step: 1, Energy: -1.26779949\n",
      "--- Step: 2, Energy: -1.27110529\n",
      "--- Step: 3, Energy: -1.27269203\n",
      "--- Step: 4, Energy: -1.27345238\n",
      "--- Step: 5, Energy: -1.27381655\n",
      "--- Step: 6, Energy: -1.27399097\n",
      "--- Step: 7, Energy: -1.27407452\n",
      "--- Step: 8, Energy: -1.27411455\n",
      "--- Step: 9, Energy: -1.27413373\n",
      "Final angle parameters: [0.18356278 0.1841571 ]\n"
     ]
    }
   ],
   "source": [
    "@qjit\n",
    "def grad_descent_step(params, stepsize: float):\n",
    "    diff = catalyst.grad(catalyst_cost_func, argnum=0)\n",
    "    return params - diff(params) * stepsize\n",
    "\n",
    "theta = jnp.array([0.0, 0.0])\n",
    "\n",
    "for i in range(10):\n",
    "    theta = grad_descent_step(theta, 0.4)\n",
    "    print(f\"--- Step: {i}, Energy: {qjit(catalyst_cost_func)(theta):.8f}\")\n",
    "\n",
    "print(f\"Final angle parameters: {theta}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11ad1a6f",
   "metadata": {},
   "source": [
    "In this example, `grad_descent_walk` compiled at the first call (in the first iteration) and was cached effectively so that in subsequent calls you could see an order-of-magnitude speedup. Even with our custom implementation of gradient descent, this is faster than that PennyLane's VQE implementation (with `qml.GradientDescentOptimizer` and PennyLane-Lightning as the backend simulator), showing another advantage of JIT compilation and Catalyst.\n",
    "\n",
    "You can also execute the `grad_descent_step` in the ahead-of-time (AOT) mode to trigger compilation even before the first call by using `jax.core.ShapedArray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebb241f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step: 0, Energy: -1.26094188\n",
      "--- Step: 1, Energy: -1.26779949\n",
      "--- Step: 2, Energy: -1.27110529\n",
      "--- Step: 3, Energy: -1.27269203\n",
      "--- Step: 4, Energy: -1.27345238\n",
      "--- Step: 5, Energy: -1.27381655\n",
      "--- Step: 6, Energy: -1.27399097\n",
      "--- Step: 7, Energy: -1.27407452\n",
      "--- Step: 8, Energy: -1.27411455\n",
      "--- Step: 9, Energy: -1.27413373\n",
      "Final angle parameters: [0.18356278 0.1841571 ]\n"
     ]
    }
   ],
   "source": [
    "from jax.core import ShapedArray\n",
    "\n",
    "@qjit\n",
    "def grad_descent_step_aot(params: ShapedArray([2], float), stepsize: float):\n",
    "    diff = catalyst.grad(catalyst_cost_func, argnum=0)\n",
    "    return params - diff(params) * stepsize\n",
    "\n",
    "theta = jnp.array([0.0, 0.0])\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    theta = grad_descent_step_aot(theta, 0.4)\n",
    "    print(f\"--- Step: {i}, Energy: {qjit(catalyst_cost_func)(theta):.8f}\")\n",
    "\n",
    "print(f\"Final angle parameters: {theta}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5022405",
   "metadata": {},
   "source": [
    "## Adaptive VQE for $LiH$ with Catalyst\n",
    "\n",
    "For certain problems, considering all possible excitations can drastically increase the cost of simulation without improving the accuracy of results. In this case, one strategy to reduce the complexity is to use <i>adaptive circuits</i>, customized for the molecule at hand and taking into account only those excitations that are found to be important. Applying VQE to this adapted circuit is called Adaptive VQE.\n",
    "\n",
    "In the second part of this tutorial, you will learn how to implement the Adaptive VQE to $LiH$ (lithium hydride) using Catalyst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf479007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qubits: 10\n",
      "single_gates: 8\n",
      "double_gates: 16\n",
      "hf: [1 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "symbols = [\"Li\", \"H\"]\n",
    "coordinates = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 2.969280527])\n",
    "\n",
    "# Building the molecular hamiltonian for LiH\n",
    "hamiltonian, qubits = qml.qchem.molecular_hamiltonian(\n",
    "    symbols,\n",
    "    coordinates,\n",
    "    active_electrons=2,\n",
    "    active_orbitals=5\n",
    ")\n",
    "\n",
    "print(f\"qubits: {qubits}\")\n",
    "\n",
    "active_electrons = 2\n",
    "\n",
    "singles, doubles = qml.qchem.excitations(active_electrons, qubits)\n",
    "\n",
    "print(f\"single_gates: {len(singles)}\")\n",
    "print(f\"double_gates: {len(doubles)}\")\n",
    "\n",
    "## The Hartree-Fock state \n",
    "hf = qml.qchem.hf_state(active_electrons, qubits)\n",
    "\n",
    "print(f\"hf: {hf}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25ed2227",
   "metadata": {},
   "source": [
    "In this example, there are a total of 8 single + 16 double = 24 excitations. Rather than include all of them, we will adaptively select the most relevant ones as follows:\n",
    "\n",
    "1. Compute gradients for all double excitations.\n",
    "2. Select the double excitations with gradients larger than a pre-defined threshold.\n",
    "3. Perform VQE to obtain the optimized parameters for the selected double excitations.\n",
    "4. Repeat steps 1 and 2 for the single excitations.\n",
    "5. Perform the final VQE optimization with all the selected excitations.\n",
    "\n",
    "### Standard PennyLane\n",
    "\n",
    "Let's first go over the implementation of these steps in the PennyLane demo on [adaptive circuits for quantum chemistry](https://pennylane.ai/qml/demos/tutorial_adaptive_circuits.html):\n",
    "\n",
    "**Step 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c80baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excitation: [0, 1, 2, 3], Gradient: -0.012782168180745672\n",
      "Excitation: [0, 1, 2, 5], Gradient: 0.0\n",
      "Excitation: [0, 1, 2, 7], Gradient: 0.0\n",
      "Excitation: [0, 1, 2, 9], Gradient: 0.03426450359905814\n",
      "Excitation: [0, 1, 3, 4], Gradient: 0.0\n",
      "Excitation: [0, 1, 3, 6], Gradient: 0.0\n",
      "Excitation: [0, 1, 3, 8], Gradient: -0.03426450359905814\n",
      "Excitation: [0, 1, 4, 5], Gradient: -0.02358152437911096\n",
      "Excitation: [0, 1, 4, 7], Gradient: 0.0\n",
      "Excitation: [0, 1, 4, 9], Gradient: 0.0\n",
      "Excitation: [0, 1, 5, 6], Gradient: 0.0\n",
      "Excitation: [0, 1, 5, 8], Gradient: 0.0\n",
      "Excitation: [0, 1, 6, 7], Gradient: -0.023581524379121893\n",
      "Excitation: [0, 1, 6, 9], Gradient: 0.0\n",
      "Excitation: [0, 1, 7, 8], Gradient: 0.0\n",
      "Excitation: [0, 1, 8, 9], Gradient: -0.12362273289626545\n"
     ]
    }
   ],
   "source": [
    "# Create a circuit that applies a selected group of gates\n",
    "# to a reference Hartree-Fock state.\n",
    "def circuit_1(params, excitations):\n",
    "    qml.BasisState(hf, wires=range(qubits))\n",
    "\n",
    "    for i, excitation in enumerate(excitations):\n",
    "        if len(excitation) == 4:\n",
    "            qml.DoubleExcitation(params[i], wires=excitation)\n",
    "        else:\n",
    "            qml.SingleExcitation(params[i], wires=excitation)\n",
    "    return qml.expval(hamiltonian)\n",
    "\n",
    "# Define the device and the cost function.\n",
    "dev = qml.device(\"lightning.qubit\", wires=qubits)\n",
    "cost_fn = qml.QNode(circuit_1, dev, diff_method=\"adjoint\")\n",
    "cost_fn = decompose(stopping_condition, cost_fn)\n",
    "\n",
    "circuit_gradient = qml.grad(cost_fn, argnum=0)\n",
    "\n",
    "# Initialize the parameter values to zero such that the gradients\n",
    "# are computed w.r.t the Hartree-Fock state.\n",
    "params = [0.0] * len(doubles)\n",
    "grads = circuit_gradient(params, excitations=doubles)\n",
    "\n",
    "for i in range(len(doubles)):\n",
    "    print(f\"Excitation: {doubles[i]}, Gradient: {grads[i]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e330f69",
   "metadata": {},
   "source": [
    "**Step 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ed9361f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doubles_select: [[0, 1, 2, 3], [0, 1, 2, 9], [0, 1, 3, 8], [0, 1, 4, 5], [0, 1, 6, 7], [0, 1, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "# Select those gates that have non-trivial gradient\n",
    "doubles_select = [\n",
    "    doubles[i] for i in range(len(doubles)) if abs(grads[i]) > 1.0e-5\n",
    "]\n",
    "print(f\"doubles_select: {doubles_select}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fd37765",
   "metadata": {},
   "source": [
    "**Step 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35c4d688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_doubles: [ 0.04758607 -0.09855449  0.09865961  0.05330068  0.05331785  0.22938117]\n"
     ]
    }
   ],
   "source": [
    "# Add the selected gates to the circuit and perform\n",
    "# one optimization step to determine the updated \n",
    "# (optimized) parameters for the selected double gates.\n",
    "opt = qml.GradientDescentOptimizer(stepsize=0.5)\n",
    "\n",
    "params_doubles = np.zeros(len(doubles_select))\n",
    "\n",
    "for n in range(20):\n",
    "    params_doubles = opt.step(cost_fn, params_doubles, excitations=doubles_select)\n",
    "\n",
    "print(f\"params_doubles: {params_doubles}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d32b5a3c",
   "metadata": {},
   "source": [
    "**Step 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3fdc69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excitation : [0, 2], Gradient: 0.005062544629162047\n",
      "Excitation : [0, 4], Gradient: 0.0\n",
      "Excitation : [0, 6], Gradient: 0.0\n",
      "Excitation : [0, 8], Gradient: 0.0009448055879244589\n",
      "Excitation : [1, 3], Gradient: -0.004926625112976867\n",
      "Excitation : [1, 5], Gradient: 0.0\n",
      "Excitation : [1, 7], Gradient: 0.0\n",
      "Excitation : [1, 9], Gradient: -0.0014535553867887066\n",
      "singles_select: [[0, 2], [0, 8], [1, 3], [1, 9]]\n"
     ]
    }
   ],
   "source": [
    "# Keep the selected gates in the circuit and compute the gradients\n",
    "# with respect to all of the single excitation gates, selecting\n",
    "# those that have a non-negligible gradient.\n",
    "# Repeat steps 1 and 2 for the single excitations.\n",
    "def circuit_2(params, excitations, gates_select, params_select):\n",
    "    qml.BasisState(hf, wires=range(qubits))\n",
    "\n",
    "    for i, gate in enumerate(gates_select):\n",
    "        if len(gate) == 4:\n",
    "            qml.DoubleExcitation(params_select[i], wires=gate)\n",
    "        elif len(gate) == 2:\n",
    "            qml.SingleExcitation(params_select[i], wires=gate)\n",
    "\n",
    "    for i, gate in enumerate(excitations):\n",
    "        if len(gate) == 4:\n",
    "            qml.DoubleExcitation(params[i], wires=gate)\n",
    "        elif len(gate) == 2:\n",
    "            qml.SingleExcitation(params[i], wires=gate)\n",
    "    return qml.expval(hamiltonian)\n",
    "\n",
    "cost_fn = qml.QNode(circuit_2, dev, diff_method=\"adjoint\")\n",
    "cost_fn = decompose(stopping_condition, cost_fn)\n",
    "circuit_gradient = qml.grad(cost_fn, argnum=0)\n",
    "params = [0.0] * len(singles)\n",
    "\n",
    "grads = circuit_gradient(\n",
    "    params,\n",
    "    excitations=singles,\n",
    "    gates_select=doubles_select,\n",
    "    params_select=params_doubles\n",
    ")\n",
    "\n",
    "for i in range(len(singles)):\n",
    "    print(f\"Excitation : {singles[i]}, Gradient: {grads[i]}\")\n",
    "\n",
    "singles_select = [singles[i] for i in range(len(singles)) if abs(grads[i]) > 1.0e-5]\n",
    "print(f\"singles_select: {singles_select}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb27182e",
   "metadata": {},
   "source": [
    "**Step 5**\n",
    "\n",
    "We now have all of the gates required to build our adaptive circuit and variationally optimize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64983d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy: -7.88223735\n"
     ]
    }
   ],
   "source": [
    "# Perform the final VQE optimization with all the selected excitations\n",
    "cost_fn = qml.QNode(circuit_1, dev, diff_method=\"adjoint\")\n",
    "\n",
    "params = np.zeros(len(doubles_select + singles_select))\n",
    "\n",
    "gates_select = doubles_select + singles_select\n",
    "\n",
    "ntrials = 20\n",
    "for n in range(ntrials):\n",
    "    params, energy = opt.step_and_cost(cost_fn, params, excitations=gates_select)\n",
    "\n",
    "print(f\"Energy: {energy:.8f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3393dd97",
   "metadata": {},
   "source": [
    "### PennyLane with Catalyst\n",
    "\n",
    "Let's repeat these steps in Catalyst, where we can take advantage of QJIT compatible control-flow operations to perform the adaptive selection and VQE.\n",
    "\n",
    "**Step 1**\n",
    "\n",
    "Let us first create a unified circuit, merging both `circuit_1` and `circuit_2`, before performing those 5 steps. The dynamically shaped arrays can't be utilized in the function body of a quantum function in Catalyst, so we will need to split the list of wires for `excitations` into two groups of single and double excitations (`double_gates` and `single_gates` in `avqe_circuit`).\n",
    "\n",
    "We then need to add a gate verifier to conditionally apply either `qml.DoubleExcitation` or `qml.SingleExcitation`, depending on the type of excitation. The first part of `catalyst_avqe_circuit` is used in steps 4 and 5 of our Adaptive VQE recipe, while the second part is a QJIT compatible version of `circuit_1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c759ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(decompose, stopping_condition)\n",
    "@qml.qnode(qml.device(\"lightning.qubit\", wires=qubits))\n",
    "def catalyst_avqe_circuit(\n",
    "    num_gates, num_selected_gates,\n",
    "    params, selected_params,\n",
    "    double_gates, single_gates,\n",
    "    selected_double_gates, selected_single_gates,\n",
    "    gates_verifier, selected_verifier,\n",
    "    apply_selected):\n",
    "    qml.BasisState(hf, wires=range(qubits))\n",
    "\n",
    "    # Used in steps 4-5\n",
    "    def include_selected_gates():\n",
    "        def apply_func(i):\n",
    "            param = selected_params[i]\n",
    "            @catalyst.cond(selected_verifier[i])\n",
    "            def apply_doubles():\n",
    "                qml.DoubleExcitation(param, selected_double_gates[i])\n",
    "            @apply_doubles.otherwise\n",
    "            def otherwise():\n",
    "                qml.SingleExcitation(param, selected_single_gates[i])\n",
    "            apply_doubles()\n",
    "\n",
    "        catalyst.for_loop(0, num_selected_gates, 1)(apply_func)()\n",
    "    catalyst.cond(apply_selected)(include_selected_gates)()\n",
    "\n",
    "    # Used in steps 1-5\n",
    "    def apply_gates(i):\n",
    "        @catalyst.cond(gates_verifier[i])\n",
    "        def apply_double():\n",
    "            qml.DoubleExcitation(params[i], double_gates[i])\n",
    "        @apply_double.otherwise\n",
    "        def otherwise():\n",
    "            qml.SingleExcitation(params[i], single_gates[i])\n",
    "        \n",
    "        apply_double()\n",
    "    catalyst.for_loop(0, num_gates, 1)(apply_gates)()\n",
    "\n",
    "    return qml.expval(\n",
    "        qml.Hamiltonian(np.array(hamiltonian.coeffs), hamiltonian.ops)\n",
    "    )\n",
    "\n",
    "\n",
    "jit_catalyst_avqe_circuit = qjit(catalyst_avqe_circuit)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cee7e4e0",
   "metadata": {},
   "source": [
    "If we set the initial parameter values to zero, the gradients will be computed with respect to the Hartree-Fock state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "327adbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excitation: [0 1 2 3], Gradient: -0.012782095382135594\n",
      "Excitation: [0 1 2 5], Gradient: 7.105427357601002e-08\n",
      "Excitation: [0 1 2 7], Gradient: 7.105427357601002e-08\n",
      "Excitation: [0 1 2 9], Gradient: 0.03426457340083289\n",
      "Excitation: [0 1 3 4], Gradient: 7.105427357601002e-08\n",
      "Excitation: [0 1 3 6], Gradient: 9.769962616701378e-08\n",
      "Excitation: [0 1 3 8], Gradient: -0.034264404646933144\n",
      "Excitation: [0 1 4 5], Gradient: -0.023581412378348432\n",
      "Excitation: [0 1 4 7], Gradient: 9.769962616701378e-08\n",
      "Excitation: [0 1 4 9], Gradient: 7.105427357601002e-08\n",
      "Excitation: [0 1 5 6], Gradient: 7.105427357601002e-08\n",
      "Excitation: [0 1 5 8], Gradient: 7.105427357601002e-08\n",
      "Excitation: [0 1 6 7], Gradient: -0.023581412378348432\n",
      "Excitation: [0 1 6 9], Gradient: 6.217248937900877e-08\n",
      "Excitation: [0 1 7 8], Gradient: 6.217248937900877e-08\n",
      "Excitation: [0 1 8 9], Gradient: -0.12362264989462801\n"
     ]
    }
   ],
   "source": [
    "@qjit\n",
    "def avqe_circuit_grad(\n",
    "    num_gates, num_selected_gates,\n",
    "    params, selected_params,\n",
    "    double_gates, single_gates,\n",
    "    selected_double_gates, selected_single_gates,\n",
    "    gates_verifier, selected_verifier,\n",
    "    apply_selected):\n",
    "    \n",
    "    g = catalyst.grad(catalyst_avqe_circuit, argnum=2, method=\"fd\")\n",
    "    return g(num_gates, num_selected_gates,\n",
    "            params, selected_params,\n",
    "            double_gates, single_gates,\n",
    "            selected_double_gates, selected_single_gates,\n",
    "            gates_verifier, selected_verifier,\n",
    "            apply_selected)\n",
    "\n",
    "num_gates = len(doubles)\n",
    "params = jnp.asarray([0.0] * num_gates)\n",
    "gates_verifier = jnp.asarray([True] * num_gates)\n",
    "doubles = jnp.asarray(doubles)\n",
    "singles = jnp.asarray(singles)\n",
    "gates_verifier = jnp.asarray(gates_verifier)\n",
    "\n",
    "grads = avqe_circuit_grad(num_gates, 1, params, jnp.asarray([0.0]), doubles, singles,\n",
    "            jnp.asarray([[-1,-1,-1,-1]]), jnp.asarray([[-1,-1]]), gates_verifier, jnp.asarray([False]), False)\n",
    "\n",
    "for i in range(len(doubles)):\n",
    "    print(f\"Excitation: {doubles[i]}, Gradient: {grads[i]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70f1c316",
   "metadata": {},
   "source": [
    "**Step 2**\n",
    "\n",
    "We'll select only those double-excitation gates with a non-trivial gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0213ff0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doubles_select: [Array([0, 1, 2, 3], dtype=int64), Array([0, 1, 2, 9], dtype=int64), Array([0, 1, 3, 8], dtype=int64), Array([0, 1, 4, 5], dtype=int64), Array([0, 1, 6, 7], dtype=int64), Array([0, 1, 8, 9], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "doubles_select = [doubles[i] for i in range(len(doubles)) if abs(grads[i]) > 1.0e-5]\n",
    "print(f\"doubles_select: {doubles_select}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df0f6f80",
   "metadata": {},
   "source": [
    "**Step 3**\n",
    "\n",
    "Now we add the selected double gates to the circuit and perform one optimization step to determine the updated (optimized) parameters associated with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c36c296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_doubles: [ 0.04758601 -0.09855455  0.09865969  0.0533007   0.0533178   0.22938115]\n"
     ]
    }
   ],
   "source": [
    "@qjit\n",
    "def grad_descent(\n",
    "    num_gates, num_selected_gates,\n",
    "    params, selected_params,\n",
    "    double_gates, single_gates,\n",
    "    selected_double_gates, selected_single_gates,\n",
    "    gates_verifier, selected_verifier,\n",
    "    apply_selected, ntrials, stepsize):\n",
    "\n",
    "    diff = catalyst.grad(catalyst_avqe_circuit, argnum=2, method=\"fd\")\n",
    "    def grad_step(i, theta):\n",
    "        h = diff(num_gates, num_selected_gates,\n",
    "                theta, selected_params,\n",
    "                double_gates, single_gates,\n",
    "                selected_double_gates, selected_single_gates,\n",
    "                gates_verifier, selected_verifier, apply_selected)\n",
    "        return theta - h * stepsize\n",
    "\n",
    "    return catalyst.for_loop(0, ntrials, 1)(grad_step)(params)\n",
    "\n",
    "num_gates = len(doubles_select)\n",
    "params_doubles = jnp.asarray([0.0] * num_gates)\n",
    "gates_verifier = jnp.asarray([True] * num_gates)\n",
    "doubles_select = jnp.asarray(doubles_select)\n",
    "singles = jnp.asarray(singles)\n",
    "ntrials = 20\n",
    "stepsize = 0.5\n",
    "\n",
    "params_doubles = grad_descent(num_gates, 1, params_doubles, jnp.asarray([0.0]), \n",
    "    doubles_select, singles, jnp.asarray([[-1,-1,-1,-1]]), jnp.asarray([[-1,-1]]), gates_verifier,\n",
    "    jnp.asarray([False]), False, ntrials, stepsize)\n",
    "\n",
    "print(f\"params_doubles: {params_doubles}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85c267ea",
   "metadata": {},
   "source": [
    "In the last two steps, we'll utilize the selected double-excitation gates in the circuit and compute the gradients with respect to all of the single-excitation gates. After this process, we can select those single-excitation gates that have non-trivial gradients and repeat the first two steps to optimize the corresponding parameters. We then perform the final VQE optimization with all the selected single- and double-excitation gates:\n",
    "\n",
    "**Step 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d04316b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "singles_select: [Array([0, 2], dtype=int64), Array([0, 8], dtype=int64), Array([1, 3], dtype=int64), Array([1, 9], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "num_gates = len(singles)\n",
    "params = jnp.asarray([0.0] * num_gates)\n",
    "gates_verifier = jnp.asarray([False] * num_gates)\n",
    "num_selected_gates = len(doubles_select)\n",
    "selected_params = jnp.asarray(params_doubles)\n",
    "selected_verifier = jnp.asarray([True] * num_selected_gates)\n",
    "apply_selected = True\n",
    "\n",
    "grads = avqe_circuit_grad(\n",
    "        num_gates, num_selected_gates,\n",
    "        params, selected_params,\n",
    "        doubles, singles, \n",
    "        doubles_select, jnp.asarray([[0,1]]),\n",
    "        gates_verifier, selected_verifier,\n",
    "        apply_selected)\n",
    "\n",
    "singles_select = [singles[i] for i in range(len(singles)) if abs(grads[i]) > 1.0e-5]\n",
    "\n",
    "print(f\"singles_select: {singles_select}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71f49f12",
   "metadata": {},
   "source": [
    "**Step 5**\n",
    "\n",
    "All of the gates now are ready to be used in the final optimization! Here goes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f737653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy: -7.88202350\n"
     ]
    }
   ],
   "source": [
    "# Selected gates\n",
    "singles_select = [[0, 2], [0, 8], [1, 3], [1, 9]]\n",
    "doubles_select = [[0, 1, 2, 3], [0, 1, 2, 9], [0, 1, 3, 8], [0, 1, 4, 5], [0, 1, 6, 7], [0, 1, 8, 9]]\n",
    "\n",
    "#gates_select = doubles_select + singles_select\n",
    "#print(gates_select)\n",
    "num_gates = len(doubles_select)\n",
    "params = jnp.asarray([0.0] * num_gates)\n",
    "gates_verifier = jnp.asarray([True] * len(doubles_select) + [False] * len(singles_select))\n",
    "casted_singles_select = jnp.asarray([[-1, -1]] * len(doubles_select) + singles_select)\n",
    "casted_doubles_select = jnp.asarray(doubles_select)\n",
    "ntrials = 20\n",
    "stepsize = 0.5\n",
    "\n",
    "params = grad_descent(num_gates, 1, params, jnp.asarray([0.0]), casted_doubles_select, casted_singles_select,\n",
    "    jnp.asarray([[-1,-1,-1,-1]]), jnp.asarray([[-1,-1]]), gates_verifier, jnp.asarray([False]), False, ntrials, stepsize)\n",
    "\n",
    "opt_energy = jit_catalyst_avqe_circuit(num_gates, 1, params, jnp.asarray([0.0]), casted_doubles_select,\n",
    "    casted_singles_select, jnp.asarray([[-1,-1,-1,-1]]), jnp.asarray([[-1,-1]]), gates_verifier, jnp.asarray([False]), False)\n",
    "\n",
    "print(f\"Energy: {opt_energy:.8f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebcb42a0",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f00b428",
   "metadata": {},
   "source": [
    "In this tutorial, we've seen some of Catalyst's features, including the JIT and AOT compilers and QJIT compatible gradient and control-flow operations. It's important to remember that this compiler is still an experimental project, and there may be bugs and corner cases. That said, here are a few key takeaways:\n",
    "\n",
    "- *PennyLane compatibility*: Catalyst provides support for core functionalities of PennyLane with a similar user interface. Some of the features may not be fully supported yet, but future plans include the addition of more.\n",
    "- *Comparable performance*: The Catalyst JIT/AOT compiler has the capability to convert PennyLane programs into machine code. It is projected to yield execution performance that is comparable to that of interpreted Python code, particularly when there are multiple calls of a JIT-compiled function in a program. It is important to take into consideration that the overhead of the compilation process may impact the performance of relatively small programs.\n",
    "- *Reduced memory usage*: Catalyst can also help to reduce the memory usage of PennyLane programs by eliminating the need to keep the original source code in memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f595fc1051784cac2f74f4882ec4da91e7d9fe5b9f2521ac37107ad816d0ce3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
